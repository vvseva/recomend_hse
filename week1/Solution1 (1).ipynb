{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Реализация базовых метрик\n",
    "\n",
    "Ваша задача реализовать основные метрики которые мы сегодня обсудили и сравнить их на игрушечном примере."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserRatings = {\\\n",
    "               \"User1\": [5,3,5,2,1,5,1,5,4,4],\\\n",
    "               \"User2\": [3,3,3,2,2,3,3,5,4,5],\\\n",
    "               \"User3\": [1,5,5,1,1,3,3,3,4,5]\\\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model1Ratings = {\\\n",
    "               \"User1\": [1,3,4,2,2,4,3,4,4,4],\\\n",
    "               \"User2\": [1,3,4,2,1,3,2,5,5,5],\\\n",
    "               \"User3\": [1,3,5,1,3,4,4,5,4,3]\\\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model2Ratings = {\\\n",
    "               \"User1\": [5,4,5,4,2,3,2,5,5,5],\\\n",
    "               \"User2\": [4,4,3,3,1,2,2,3,3,5],\\\n",
    "               \"User3\": [3,5,5,2,4,2,2,4,4,4]\\\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выше вам даны оценки которые пользователи поставили фильмам и оценки которые предложили две модели. \n",
    "\n",
    "*Задача 1:* Вычислите MAE, MSE и RMSE для этих моделей. Какая модель лучше?\n",
    "\n",
    "*Задача 2:* Реализуйте функцию Recomend(MarkList, N) которая по списку оценок выводит лист из N id фильмов, соответствующих лучшим оценкам. При равенстве оценок лучше считается вильм с меньшим id. id фильма соответствует индекcу в MarkList. \n",
    "\n",
    "*Задача 3:* Для каждого пользователя и для каждой модели постройте рекомендацию 5 лучших фильмов, используя функцию  Recomend(MarkList, N). Считая настоящие(UserRatings) оценки положительными в случае 5 или 4 и отрицательными во всех других случаях, посчитайте precision, recall и roc_auc.\n",
    "\n",
    "*Задача 4:* Посчитайте NDCG для построенной выше рекомендации с бинарными оценками.\n",
    "\n",
    "*Задача 5:* Посчитайте NDCG для построенной выше рекомендации, считая что $r_i=2$, при оценке 5, $r_i=1$, при оценке 4, $r_i=0$, в остальных случаях.  \n",
    "\n",
    "*Задача 6:* Сравните модели по всем метрикам.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE(RealRatings, ModelRatings):\n",
    "    summa = 0\n",
    "    cnt = 0\n",
    "    for usr in ModelRatings:\n",
    "        for i in range(len(ModelRatings[usr])):\n",
    "            summa += abs(ModelRatings[usr][i] - RealRatings[usr][i])\n",
    "            cnt += 1\n",
    "    return summa / cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(RealRatings, ModelRatings):\n",
    "    summa = 0\n",
    "    cnt = 0\n",
    "    for usr in ModelRatings:\n",
    "        for i in range(len(ModelRatings[usr])):\n",
    "            summa += (ModelRatings[usr][i] - RealRatings[usr][i])**2\n",
    "            cnt += 1\n",
    "    return summa / cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAE(UserRatings, Model1Ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAE(UserRatings, Model2Ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6666666666666667"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE(UserRatings, Model1Ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE(UserRatings, Model2Ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Recomend(MarkList, N):\n",
    "    order = [x for x in range(len(MarkList))]\n",
    "    return sorted(order, reverse = True, key = lambda x: (MarkList[x], -x))[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 5, 7, 8, 9, 1, 6, 3, 4, 0]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Recomend(Mode1Ratings[\"User1\"], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38461538461538464 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "N = 2\n",
    "good = 0\n",
    "cnt = 0\n",
    "for u in UserRatings:\n",
    "    res = Recomend(Mode1Ratings[u], N)\n",
    "    for i in res:\n",
    "        if UserRatings[u][i]>3: good += 1\n",
    "        cnt += 1\n",
    "\n",
    "recall = good/cnt\n",
    "\n",
    "TotalGood = 0\n",
    "\n",
    "for u in UserRatings:\n",
    "    for i in UserRatings[u]:\n",
    "        if i>3: TotalGood += 1\n",
    "\n",
    "precision = good/TotalGood\n",
    "\n",
    "print(precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log2\n",
    "def NDCGk(real_values, model_order, rfunc, k):\n",
    "    ideal_score = sorted([rfunc(x) for x in real_values], reverse = True)\n",
    "    model_score = [rfunc(real_values[x]) for x in model_order] \n",
    "    #print(ideal_score)\n",
    "    #print(model_score)\n",
    "    DCG = 0\n",
    "    iDCG = 0\n",
    "    for i in range(k):\n",
    "        DCG += 2**model_score[i]/log2(i+2)\n",
    "    for i in range(k):\n",
    "        iDCG += 2**ideal_score[i]/log2(i+2)\n",
    "    return (DCG/iDCG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def more3(x):\n",
    "    if x > 3: \n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ver2(x):\n",
    "    if x == 5:\n",
    "        return 2\n",
    "    elif x == 4:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 1, 1, 0, 0, 0, 0]\n",
      "[2, 2, 2, 1, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9218382134470557"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NDCGk(UserRatings[\"User1\"], Recomend(Model1Ratings[\"User1\"], 5),ver2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9405241729242503 0.9458572302014999\n"
     ]
    }
   ],
   "source": [
    "sum1 = 0\n",
    "sum2 = 0\n",
    "N = 10\n",
    "for u in Model1Ratings:\n",
    "    sum1 += NDCGk(UserRatings[u], Recomend(Model1Ratings[u], N),ver2, N)\n",
    "    sum2 += NDCGk(UserRatings[u], Recomend(Model2Ratings[u], N),ver2, N)\n",
    "print(sum1/3, sum2/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
