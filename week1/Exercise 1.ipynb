{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Реализация базовых метрик\n",
    "\n",
    "Ваша задача реализовать основные метрики которые мы сегодня обсудили и сравнить их на игрушечном примере."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'User1': [5, 3, 5, 2, 1, 5, 1, 5, 4, 4],\n 'User2': [3, 3, 3, 2, 2, 3, 3, 5, 4, 5],\n 'User3': [1, 5, 5, 1, 1, 3, 3, 3, 4, 5]}"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UserRatings = {\\\n",
    "               \"User1\": [5,3,5,2,1,5,1,5,4,4],\\\n",
    "               \"User2\": [3,3,3,2,2,3,3,5,4,5],\\\n",
    "               \"User3\": [1,5,5,1,1,3,3,3,4,5]\\\n",
    "              }\n",
    "UserRatings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model1Ratings = {\\\n",
    "               \"User1\": [1,3,4,2,2,4,3,4,4,4],\\\n",
    "               \"User2\": [1,3,4,2,1,3,2,5,5,5],\\\n",
    "               \"User3\": [1,3,5,1,3,4,4,5,4,3]\\\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model2Ratings = {\\\n",
    "               \"User1\": [5,4,5,4,2,3,2,5,5,5],\\\n",
    "               \"User2\": [4,4,3,3,1,2,2,3,3,5],\\\n",
    "               \"User3\": [3,5,5,2,4,2,2,4,4,4]\\\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выше вам даны оценки которые пользователи поставили фильмам и оценки которые предложили две модели. \n",
    "\n",
    "*Задача 1:* Вычислите MAE, MSE и RMSE для этих моделей. Какая модель лучше?\n",
    "\n",
    "*Задача 2:* Реализуйте функцию Recomend(MarkList, N) которая по списку оценок выводит лист из N id фильмов, соответствующих лучшим оценкам. При равенстве оценок лучше считается вильм с меньшим id. id фильма соответствует индекcу в MarkList. \n",
    "\n",
    "*Задача 3:* Для каждого пользователя и для каждой модели постройте рекомендацию 5 лучших фильмов, используя функцию  Recomend(MarkList, N). Считая настоящие(UserRatings) оценки положительными в случае 5 или 4 и отрицательными во всех других случаях, посчитайте precision, recall и roc_auc.\n",
    "\n",
    "*Задача 4:* Посчитайте NDCG для построенной выше рекомендации с бинарными оценками.\n",
    "\n",
    "*Задача 5:* Посчитайте NDCG для построенной выше рекомендации, считая что $r_i=2$, при оценке 5, $r_i=1$, при оценке 4, $r_i=0$, в остальных случаях.  \n",
    "\n",
    "*Задача 6:* Сравните модели по всем метрикам.\n",
    "\n",
    "# Задача 1: Вычислите MAE, MSE и RMSE для этих моделей. Какая модель лучше?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tr_df = pd.DataFrame.from_dict(UserRatings)\n",
    "pr_df = pd.DataFrame.from_dict(Model1Ratings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "0.13333333333333333"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_df = pd.wide_to_long((tr_df - pr_df).reset_index(),\n",
    "                stubnames='User', i = \"index\", j = \"id\").reset_index()\n",
    "error_df.User.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MAE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_mae(true, predicted):\n",
    "    '''\n",
    "    :param true: real rating, dictionary\n",
    "    :param predicted: model result, dictionaru\n",
    "    :return: int, mean error\n",
    "    '''\n",
    "    tr_df = pd.DataFrame.from_dict(true)\n",
    "    pr_df = pd.DataFrame.from_dict(predicted)\n",
    "    error_df = pd.wide_to_long((tr_df - pr_df).reset_index(),\n",
    "                               stubnames='User', i = \"index\", j = \"id\").reset_index()\n",
    "    return(error_df.User.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1, MAE:\n",
      "0.13333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"Model 1, MAE:\")\n",
    "print(my_mae(UserRatings, Model1Ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2, MAE:\n",
      "-0.2\n"
     ]
    }
   ],
   "source": [
    "print(\"Model 2, MAE:\")\n",
    "print(my_mae(UserRatings, Model2Ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MSE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def my_mse(true, predicted):\n",
    "    '''\n",
    "    :param true: real rating, dictionary\n",
    "    :param predicted: model result, dictionaru\n",
    "    :return: int, mean square error\n",
    "    '''\n",
    "    tr_df = pd.DataFrame.from_dict(true)\n",
    "    pr_df = pd.DataFrame.from_dict(predicted)\n",
    "    error_df = pd.wide_to_long((tr_df - pr_df).reset_index(),\n",
    "                               stubnames='User', i = \"index\", j = \"id\").reset_index()\n",
    "    print(\"MSE\")\n",
    "    return(error_df.User.pow(2).mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1\n",
      "MSE\n",
      "1.6666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"Model 1\")\n",
    "print(my_mse(UserRatings, Model1Ratings))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2\n",
      "MSE\n",
      "1.4\n"
     ]
    }
   ],
   "source": [
    "print(\"Model 2\")\n",
    "print(my_mse(UserRatings, Model2Ratings))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RMSE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def my_rmse(true, predicted):\n",
    "    '''\n",
    "    :param true: real rating, dictionary\n",
    "    :param predicted: model result, dictionaru\n",
    "    :return: int, mean square error\n",
    "    '''\n",
    "    tr_df = pd.DataFrame.from_dict(true)\n",
    "    pr_df = pd.DataFrame.from_dict(predicted)\n",
    "    error_df = pd.wide_to_long((tr_df - pr_df).reset_index(),\n",
    "                               stubnames='User', i = \"index\", j = \"id\").reset_index()\n",
    "    print(\"RMSE\")\n",
    "    return(error_df.User.pow(2).pow(1./2).mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1\n",
      "RMSE\n",
      "0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"Model 1\")\n",
    "print(my_rmse(UserRatings, Model1Ratings))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2\n",
      "RMSE\n",
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"Model 2\")\n",
    "print(my_rmse(UserRatings, Model2Ratings))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# *Задача 2:* Реализуйте функцию Recomend(MarkList, N) которая по списку оценок выводит лист из N id фильмов, соответствующих лучшим оценкам. При равенстве оценок лучше считается вильм с меньшим id. id фильма соответствует индекcу в MarkList."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "0    0\n1    2\n2    5\n3    7\n4    8\n5    9\n6    1\n7    3\n8    4\n9    6\nName: index, dtype: int64"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arr = np.array(UserRatings[\"User1\"])\n",
    "df = pd.DataFrame(UserRatings[\"User1\"], columns =['rating'])\n",
    "df.sort_values(by = [\"rating\"], ascending=False).reset_index()['index'].head(100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Recomend(MarkList, N):\n",
    "    df = pd.DataFrame(MarkList, columns =['rating'])\n",
    "    return(df.sort_values(by = [\"rating\"], ascending=False)\\\n",
    "        .reset_index()\\\n",
    "        .head(N)\\\n",
    "        .rename(columns={'rating':'predicted_rating'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "   index  predicted_rating\n0      0                 5\n1      2                 5\n2      5                 5\n3      7                 5\n4      8                 4\n5      9                 4\n6      1                 3\n7      3                 2\n8      4                 1\n9      6                 1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>predicted_rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>9</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>6</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Recomend(UserRatings[\"User1\"], 100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# *Задача 3:* Для каждого пользователя и для каждой модели постройте рекомендацию 5 лучших фильмов, используя функцию  Recomend(MarkList, N). Считая настоящие(UserRatings) оценки положительными в случае 5 или 4 и отрицательными во всех других случаях, посчитайте precision, recall и roc_auc."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "   index  rating  predicted_rating   real  predicted result\n0      1       3                 3  False      False     TN\n1      2       3                 4  False       True     FP\n2      7       5                 5   True       True     TP\n3      8       4                 5   True       True     TP\n4      9       5                 5   True       True     TP",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>rating</th>\n      <th>predicted_rating</th>\n      <th>real</th>\n      <th>predicted</th>\n      <th>result</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>False</td>\n      <td>False</td>\n      <td>TN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>False</td>\n      <td>True</td>\n      <td>FP</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7</td>\n      <td>5</td>\n      <td>5</td>\n      <td>True</td>\n      <td>True</td>\n      <td>TP</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8</td>\n      <td>4</td>\n      <td>5</td>\n      <td>True</td>\n      <td>True</td>\n      <td>TP</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9</td>\n      <td>5</td>\n      <td>5</td>\n      <td>True</td>\n      <td>True</td>\n      <td>TP</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rec_five(user, real, predicted):\n",
    "    df = pd.DataFrame(real[user], columns =['rating']).\\\n",
    "        reset_index()\n",
    "    df = df.merge(Recomend(predicted[user], 5))\n",
    "    df['real'] = df['rating']>3\n",
    "    df['predicted'] = df['predicted_rating']>3\n",
    "\n",
    "    conditions = [\n",
    "        (df['real'] == True) & (df['predicted'] == True),\n",
    "        (df['real'] == False) & (df['predicted'] == False),\n",
    "        (df['real'] == False) & (df['predicted'] == True),\n",
    "        (df['real'] == True) & (df['predicted'] == False)]\n",
    "    choices = ['TP', 'TN', 'FP', 'FN']\n",
    "    df['result'] = np.select(conditions, choices, default='error')\n",
    "\n",
    "    return(df)\n",
    "\n",
    "df = rec_five(\"User2\", UserRatings, Model1Ratings)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Precision"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "def my_precision(user, real, predicted):\n",
    "    df = rec_five(user, real, predicted)\n",
    "    tp = len(df[df['result']==\"TP\"])\n",
    "    fp = len(df[df['result']==\"FP\"])\n",
    "    pr = tp / (tp + fp)\n",
    "    return(pr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "0.4"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_precision(\"User3\", UserRatings, Model1Ratings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RECAlL"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_recall(user, real, predicted):\n",
    "    df = rec_five(user, real, predicted)\n",
    "    tp = len(df[df['result']==\"TP\"])\n",
    "    fn = len(df[df['result']==\"FN\"])\n",
    "    rc = tp / (tp + fn)\n",
    "    return(rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_recall(\"User3\", UserRatings, Model1Ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## roc_auc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def my_roc_auc(user, real, predicted):\n",
    "    y_true = rec_five(user, real, predicted).real\n",
    "    y_score = rec_five(user, real, predicted).predicted\n",
    "    score = roc_auc_score(y_true, y_score)\n",
    "    return(score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_roc_auc(\"User3\", UserRatings, Model1Ratings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Задача 4: Посчитайте NDCG для построенной выше рекомендации с бинарными оценками."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "data": {
      "text/plain": "   index  rating  predicted_rating   real  predicted result\n0      2       5                 5   True       True     TP\n1      5       3                 4  False       True     FP\n2      6       3                 4  False       True     FP\n3      7       3                 5  False       True     FP\n4      8       4                 4   True       True     TP",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>rating</th>\n      <th>predicted_rating</th>\n      <th>real</th>\n      <th>predicted</th>\n      <th>result</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>5</td>\n      <td>5</td>\n      <td>True</td>\n      <td>True</td>\n      <td>TP</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>3</td>\n      <td>4</td>\n      <td>False</td>\n      <td>True</td>\n      <td>FP</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>3</td>\n      <td>4</td>\n      <td>False</td>\n      <td>True</td>\n      <td>FP</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7</td>\n      <td>3</td>\n      <td>5</td>\n      <td>False</td>\n      <td>True</td>\n      <td>FP</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8</td>\n      <td>4</td>\n      <td>4</td>\n      <td>True</td>\n      <td>True</td>\n      <td>TP</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rec_five(user, real, predicted)\n",
    "rec_five(\"User3\", UserRatings, Model1Ratings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def my_DCG(user, real, predicted):\n",
    "#     rec_five(user, real, predicted)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def my_NDCG(user, real, predicted):\n",
    "#     rec_five(user, real, predicted)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "from math import log2\n",
    "def NDCGk(real_values, model_order, rfunc, k):\n",
    "    ideal_score = sorted([rfunc(x) for x in real_values], reverse = True)\n",
    "    model_score = [rfunc(real_values[x]) for x in model_order]\n",
    "\n",
    "    DCG = 0\n",
    "    iDCG = 0\n",
    "    for i in range(k):\n",
    "        DCG += 2**model_score[i]/log2(i+2)\n",
    "    for i in range(k):\n",
    "        iDCG += 2**ideal_score[i]/log2(i+2)\n",
    "    return (DCG/iDCG)\n",
    "\n",
    "def ver2(x):\n",
    "    if x == 5:\n",
    "        return 2\n",
    "    elif x == 4:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9218382134470557"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NDCGk(UserRatings[\"User1\"], Recomend(Model1Ratings[\"User1\"], 5)['index'],ver2, 5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9405241729242503 0.9458572302014999\n"
     ]
    }
   ],
   "source": [
    "sum1 = 0\n",
    "sum2 = 0\n",
    "N = 10\n",
    "for u in Model1Ratings:\n",
    "    sum1 += NDCGk(UserRatings[u], Recomend(Model1Ratings[u], N)['index'],ver2, N)\n",
    "    sum2 += NDCGk(UserRatings[u], Recomend(Model2Ratings[u], N)['index'],ver2, N)\n",
    "print(sum1/3, sum2/3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}